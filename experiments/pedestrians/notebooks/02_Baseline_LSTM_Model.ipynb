{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd86cc3-0026-4b4d-a52f-ed18cf671fe5",
   "metadata": {},
   "source": [
    "## Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93da1b15-f0db-4a10-825f-2c9b113ef0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 364 sequences for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/jp9n5hyx0zn9qhbx2whtfdh40000gn/T/ipykernel_92467/2611770673.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  samples = torch.load(processed_data_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the tensors you just saved\n",
    "processed_data_path = '../processed/eth_test_sequences.pt'\n",
    "samples = torch.load(processed_data_path)\n",
    "\n",
    "# Quick check to ensure the hand-off worked\n",
    "print(f\"Successfully loaded {len(samples)} sequences for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f31ae-9ed4-48c2-8802-5b60ede61381",
   "metadata": {},
   "source": [
    "## Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da3bdca-5b54-49f9-b652-4580cb706e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train_loader is ready with 12 batches.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Redefine the class so this notebook understands the data structure\n",
    "class PedestrianDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        obs, target = self.samples[idx]\n",
    "        return torch.tensor(obs, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "# 2. Re-wrap the 'samples' you successfully loaded earlier\n",
    "dataset = PedestrianDataset(samples)\n",
    "\n",
    "# 3. NOW run the loader\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"✅ train_loader is ready with {len(train_loader)} batches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b3d1d-fb78-490c-8633-5248cf4d3282",
   "metadata": {},
   "source": [
    "## The LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96a6100-bf9c-4ea2-8cf0-34f9cda365c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64, num_layers=1):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, output_size=2, hidden_size=64, num_layers=1):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # Predict one step at a time\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class TrajectoryPredictor(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64, output_len=12):\n",
    "        super(TrajectoryPredictor, self).__init__()\n",
    "        self.encoder = LSTMEncoder(input_size, hidden_size)\n",
    "        self.decoder = LSTMDecoder(input_size, hidden_size)\n",
    "        self.output_len = output_len\n",
    "        \n",
    "    def forward(self, obs_seq):\n",
    "        batch_size = obs_seq.size(0)\n",
    "        hidden, cell = self.encoder(obs_seq)\n",
    "        \n",
    "        # Start decoding from the last observed position\n",
    "        decoder_input = obs_seq[:, -1:, :] \n",
    "        outputs = []\n",
    "        \n",
    "        for _ in range(self.output_len):\n",
    "            prediction, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs.append(prediction)\n",
    "            decoder_input = prediction # Feed the prediction back as next input\n",
    "            \n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480f9f6-6363-4470-9064-c41c668ec84c",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447d93c7-b36c-403d-ab1d-c701edfa8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TrajectoryPredictor(input_size=2, hidden_size=128, output_len=12)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "from torch.utils.data import DataLoader\n",
    "# Assuming you wrapped 'samples' in your PedestrianDataset class again\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9492f94-07d5-4781-a794-e46b96da81fa",
   "metadata": {},
   "source": [
    "## The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8934cd0-cb3a-484d-bae0-d51aa5f2f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch [10/50], Loss: 4.6120\n",
      "Epoch [20/50], Loss: 0.9244\n",
      "Epoch [30/50], Loss: 0.8138\n",
      "Epoch [40/50], Loss: 0.5191\n",
      "Epoch [50/50], Loss: 0.4973\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs determines how many times the model sees the entire dataset\n",
    "num_epochs = 50 \n",
    "print(\"Starting Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for obs, target in train_loader:\n",
    "        # 1. Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass: model makes a prediction [8, 2] -> [12, 2]\n",
    "        prediction = model(obs)\n",
    "        \n",
    "        # 3. Calculate Loss (MSE): how far is the guess from reality?\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        # 4. Backward pass: calculate how to adjust weights\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Step: update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e7d7e-ebd0-433b-ad41-bab38ba8868d",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e73edf2-0b65-4155-814b-f09157cbb3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Baseline Results:\n",
      "ADE: 0.7464 meters\n",
      "FDE: 1.0921 meters\n"
     ]
    }
   ],
   "source": [
    "def evaluate_metrics(model, loader):\n",
    "    model.eval()\n",
    "    ade_total = 0\n",
    "    fde_total = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for obs, target in loader:\n",
    "            prediction = model(obs)\n",
    "            \n",
    "            # Calculate Euclidean distance at each step\n",
    "            # dist shape: (batch, 12)\n",
    "            dist = torch.norm(prediction - target, dim=2)\n",
    "            \n",
    "            # ADE: Mean distance over the 12-step horizon\n",
    "            ade_total += torch.sum(torch.mean(dist, dim=1)).item()\n",
    "            \n",
    "            # FDE: Distance at the final (12th) step\n",
    "            fde_total += torch.sum(dist[:, -1]).item()\n",
    "            \n",
    "            total_samples += obs.size(0)\n",
    "            \n",
    "    return ade_total / total_samples, fde_total / total_samples\n",
    "\n",
    "ade, fde = evaluate_metrics(model, train_loader)\n",
    "print(f\"Final Baseline Results:\")\n",
    "print(f\"ADE: {ade:.4f} meters\")\n",
    "print(f\"FDE: {fde:.4f} meters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
